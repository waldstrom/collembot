{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Colab Inference (code-only walkthrough)\n",
        "\n",
        "This notebook mirrors the Gradio launcher but runs everything in plain Python cells so you can observe every inference step and timing. It downloads the helper `gradio_app.py`, loads the YOLO model, tiles the image, runs batch predictions, fuses detections, and visualises the output without starting a Gradio UI.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Install runtime dependencies\n",
        "\n",
        "Install the exact packages expected by the helper module. Comment out lines for packages that are already available in your runtime.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Install minimal runtime dependencies. Comment out packages you already have in your runtime.\n",
        "!pip install -q ultralytics shapely pillow torch matplotlib requests\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Configure download sources and runtime options\n",
        "\n",
        "Update the URLs below if you are hosting the weights or helper in a different location. The device and batch size are derived from your runtime capabilities so you can see when GPU is unavailable.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Configure your download locations here\n",
        "# ---------------------------------------------------------------------------\n",
        "REMOTE_BASE = 'https://collembot.ch/colab-resources/'  # hosting root with model, helper, and example image\n",
        "MODEL_URL = REMOTE_BASE + 'collembot-2025_12-yolo11x-seg.pt'\n",
        "HELPER_URL = REMOTE_BASE + 'gradio_app.py'\n",
        "EXAMPLE_URL = REMOTE_BASE + 'example.jpg'\n",
        "\n",
        "ROOT = Path('/content')\n",
        "ROOT.mkdir(exist_ok=True)\n",
        "weights_path = ROOT / 'collembot-2025_12-yolo11x-seg.pt'\n",
        "helper_path = ROOT / 'gradio_app.py'\n",
        "example_path = ROOT / 'example.jpg'\n",
        "\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "PREFERRED_DEVICE = 'cuda:0' if USE_GPU else 'cpu'\n",
        "USE_HALF = False\n",
        "BATCH_SIZE = 12 if USE_GPU else 4\n",
        "\n",
        "if USE_GPU:\n",
        "    name = torch.cuda.get_device_name(torch.cuda.current_device())\n",
        "    print(f'\u2705 GPU detected: {name}')\n",
        "else:\n",
        "    print('\u26a0\ufe0f No GPU detected. In Colab, choose GPU via Runtime > Change runtime type for faster inference.')\n",
        "print(f'Using device={PREFERRED_DEVICE}, half={USE_HALF}, batch={BATCH_SIZE}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Download helper, weights, and example image\n",
        "\n",
        "The helper is reused from the Gradio notebook, but we will call its functions directly. Downloads are forced each run to keep the notebook reproducible.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def download(url: str, dest: Path):\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()\n",
        "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(dest, 'wb') as f:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "    print(f'Downloaded {url} -> {dest}')\n",
        "\n",
        "# Download the helper, weights, and example image. They will overwrite existing copies\n",
        "# to keep the notebook reproducible.\n",
        "download(HELPER_URL, helper_path)\n",
        "download(MODEL_URL, weights_path)\n",
        "download(EXAMPLE_URL, example_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Import the helper module\n",
        "\n",
        "The helper exposes the same tiling, inference, fusion, and visualisation utilities used by the Gradio app.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import importlib.util\n",
        "\n",
        "spec = importlib.util.spec_from_file_location('gradio_app', helper_path)\n",
        "gradio_app = importlib.util.module_from_spec(spec)\n",
        "spec.loader.exec_module(gradio_app)\n",
        "print(f'Loaded helper from {helper_path}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Load the YOLO model\n",
        "\n",
        "Use the helper's `load_model` to initialise the network on the chosen device. Timing is captured so you can tell how long model loading takes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "load_start = time.time()\n",
        "model, device, half_flag = gradio_app.load_model(\n",
        "    str(weights_path),\n",
        "    preferred_device=PREFERRED_DEVICE,\n",
        "    use_half=USE_HALF,\n",
        ")\n",
        "load_end = time.time()\n",
        "print(f'Model loaded on {device} (half={half_flag}) in {load_end - load_start:.2f}s')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Load an image to analyse\n",
        "\n",
        "You can replace `example_path` with your own upload (e.g., via the Colab file sidebar). The filename is stored on the PIL image so circle detection can reuse the path.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "image_path = example_path  # swap this for your own path if desired\n",
        "image = Image.open(image_path).convert('RGB')\n",
        "image.filename = str(image_path)\n",
        "print(f'Loaded image {image_path} with size {image.size}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Tile the image\n",
        "\n",
        "Run the same tiling strategy as the Gradio app (original and shifted grids). This cell reports how many tiles are produced and previews their sizes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "tile_start = time.time()\n",
        "tiles = gradio_app.build_tiles(image, max_workers=gradio_app.CPU_WORKERS)\n",
        "tile_end = time.time()\n",
        "print(f'Generated {len(tiles)} tiles in {tile_end - tile_start:.2f}s')\n",
        "if tiles:\n",
        "    sample = tiles[0]\n",
        "    print(f\"First tile tag={sample['tag']}, offset={sample['offset']}, size={sample['tile'].size}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Run YOLO predictions on the tiles\n",
        "\n",
        "The helper's `run_model_on_tiles` is called directly with a simple progress logger so you can see batch-level timing and GPU/CPU usage.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def log_progress(frac: float, desc: str = ''):\n",
        "    percent = int(frac * 100)\n",
        "    print(f'[{percent:3d}%] {desc}')\n",
        "\n",
        "infer_start = time.time()\n",
        "raw_polys = gradio_app.run_model_on_tiles(\n",
        "    model,\n",
        "    device,\n",
        "    tiles,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    use_half=half_flag,\n",
        "    progress=log_progress,\n",
        "    progress_range=(0.0, 0.9),\n",
        ")\n",
        "infer_end = time.time()\n",
        "print(f'Collected {len(raw_polys)} raw polygons in {infer_end - infer_start:.2f}s')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Fuse overlapping detections\n",
        "\n",
        "Graph-cut fusion merges overlapping polygons across tiles. This step can be a bottleneck for large images; the timing helps you gauge its cost.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "fuse_start = time.time()\n",
        "fused = gradio_app.fuse_graphcut(raw_polys, iou_th=gradio_app.BEST_IOU, alpha=gradio_app.ALPHA)\n",
        "fuse_end = time.time()\n",
        "print(f'Fused to {len(fused)} polygons in {fuse_end - fuse_start:.2f}s')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) Filter detections to the main circle\n",
        "\n",
        "A lightweight circle detector is reused to discard polygons outside the dish area (when found). Both the circle and filtered count are printed.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "circle = gradio_app.find_main_circle(image)\n",
        "filtered = gradio_app.filter_polygons_by_circle(fused, circle)\n",
        "print(f'Circle: {circle}')\n",
        "print(f'Filtered polygons: {len(filtered)} (from {len(fused)})')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11) Visualise and export results\n",
        "\n",
        "Draw the polygons and optional circle onto the original image. The preview is shown inline and also saved for download.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "viz = gradio_app.draw_polygons(image, filtered, circle)\n",
        "output_path = ROOT / 'detections.png'\n",
        "viz.save(output_path)\n",
        "print(f'Visualisation saved to {output_path}')\n",
        "display(viz)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}